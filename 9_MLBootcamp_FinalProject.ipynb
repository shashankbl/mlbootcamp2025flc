{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "11FFJD9ABN7y5Y02cn2fko_ET6FhmI6AF",
      "authorship_tag": "ABX9TyMBuEilj/eQQ2BldomR6aJx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashankbl/mlbootcamp2025flc/blob/main/9_MLBootcamp_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Bootcamp 2025\n",
        "\n",
        "### Final Project: Train a Deep Learning model to identify Grocery item"
      ],
      "metadata": {
        "id": "DoJf9K5qna65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "W9Dh8fuk22i9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Create directory 'Datasets/GroceryStoreDataset', unzip the shared dataset in it and mount the Google Drive\n",
        "# The original dataset used is: https://www.kaggle.com/datasets/validmodel/grocery-store-dataset?resource=download and it has been reduced further for our use-case\n",
        "data_dir = '/content/drive/MyDrive/Datasets/GroceryStoreDataset'  # Mount dataset in Google Drive"
      ],
      "metadata": {
        "id": "i9aVO01L27cu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ],
      "metadata": {
        "id": "DiJakegpcKuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc17f948-e33f-4832-8983-ae2dfd72271c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_class_names(csv_file_path):\n",
        "    \"\"\"\n",
        "    Extracts class names from a CSV file and returns them as a list.\n",
        "\n",
        "    Args:\n",
        "        csv_file_path (str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing a list of class names and the number of classes.\n",
        "               Returns (None, 0) if the file does not exist or an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(csv_file_path, 'r') as file:\n",
        "            reader = csv.reader(file)\n",
        "            next(reader)  # Skip header row if it exists\n",
        "            class_names = [row[2] for row in reader]  # Assuming class names are in the first column\n",
        "            class_names = sorted(set(class_names))\n",
        "        return class_names, len(class_names)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{csv_file_path}' not found.\")\n",
        "        return None, 0\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, 0"
      ],
      "metadata": {
        "id": "0czv7aeM3wTU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and normalization\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "metadata": {
        "id": "u8SYV_DN4HLk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify that all folders are accessible from mounted Google Drive\n",
        "for x in ['train', 'test']:\n",
        "  path_new = os.path.join(data_dir, x)\n",
        "  print(path_new)\n",
        "  for folder in os.listdir(path_new):\n",
        "    folder_path = os.path.join(path_new, folder)\n",
        "    print(folder_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzWojEfRI_mG",
        "outputId": "a16992a0-56cf-4ca5-e620-355bf75bab64"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Avocado\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Pomegranate\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Lemon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Kiwi\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Cucumber\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Vine-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Granny-Smith\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Watermelon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Plum\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Red-Beet\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Carrots\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Nectarine\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Lime\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Cantaloupe\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Red-Grapefruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Mango\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Red-Delicious\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Solid-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Banana\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Passion-Fruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Cabbage\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Yellow-Onion\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Zucchini\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Ginger\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Asparagus\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Papaya\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Garlic\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Peach\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Pineapple\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Sweet-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Leek\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Orange\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Pepper\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/train/Regular-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Avocado\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Lemon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Kiwi\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Vine-Tomato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Pomegranate\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Cucumber\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Cantaloupe\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Nectarine\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Granny-Smith\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Plum\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Red-Grapefruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Carrots\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Watermelon\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Lime\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Red-Beet\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Mango\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Red-Delicious\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Cabbage\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Asparagus\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Yellow-Onion\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Ginger\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Solid-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Banana\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Passion-Fruit\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Zucchini\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Papaya\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Sweet-Potato\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Pineapple\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Pepper\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Garlic\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Leek\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Peach\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Orange\n",
            "/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Regular-Tomato\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'test']}  # Assuming you have train and test folders\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'test']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
        "\n",
        "print(f\"Dataset sizes: {dataset_sizes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxlSKZia4Nnq",
        "outputId": "2b34a559-559d-4fcc-a267-0e096bd820b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizes: {'train': 1239, 'test': 1205}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "class_names = image_datasets['test'].classes\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))\n",
        "\n",
        "num_classes = len(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQfGgMDJJzbS",
        "outputId": "2b4903c5-cc0b-4227-9184-6144bee0416e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Asparagus', 'Avocado', 'Banana', 'Cabbage', 'Cantaloupe', 'Carrots', 'Cucumber', 'Garlic', 'Ginger', 'Granny-Smith', 'Kiwi', 'Leek', 'Lemon', 'Lime', 'Mango', 'Nectarine', 'Orange', 'Papaya', 'Passion-Fruit', 'Peach', 'Pepper', 'Pineapple', 'Plum', 'Pomegranate', 'Red-Beet', 'Red-Delicious', 'Red-Grapefruit', 'Regular-Tomato', 'Solid-Potato', 'Sweet-Potato', 'Vine-Tomato', 'Watermelon', 'Yellow-Onion', 'Zucchini']\n",
            "34\n",
            "['Asparagus', 'Avocado', 'Banana', 'Cabbage', 'Cantaloupe', 'Carrots', 'Cucumber', 'Garlic', 'Ginger', 'Granny-Smith', 'Kiwi', 'Leek', 'Lemon', 'Lime', 'Mango', 'Nectarine', 'Orange', 'Papaya', 'Passion-Fruit', 'Peach', 'Pepper', 'Pineapple', 'Plum', 'Pomegranate', 'Red-Beet', 'Red-Delicious', 'Red-Grapefruit', 'Regular-Tomato', 'Solid-Potato', 'Sweet-Potato', 'Vine-Tomato', 'Watermelon', 'Yellow-Onion', 'Zucchini']\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained EfficientNetB4\n",
        "model = models.efficientnet_b4(pretrained=True)\n",
        "\n",
        "# Modify the classifier\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "-HTLL6AAcz85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "569fefa3-239f-4c18-a0d9-6126e61dee94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth\n",
            "100%|██████████| 74.5M/74.5M [00:00<00:00, 156MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-63de13782e9f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Modify the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, class_names):\n",
        "  img = Image.open(image_path).convert('RGB')\n",
        "  img_t = data_transforms['test'](img).unsqueeze(0)\n",
        "  img_t = img_t.to(device)\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    out = model(img_t)\n",
        "    _, index = torch.max(out, 1)\n",
        "    percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "    print(f\"Predicted Class: {class_names[index[0]]}, Confidence: {percentage[index[0]].item():.2f}%\")"
      ],
      "metadata": {
        "id": "xiQz7UkGmp-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        now = datetime.now()\n",
        "        print(now.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'test']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            i = 0\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                i += 1\n",
        "                if i % 10 == 0:\n",
        "                    print(f\"Batch {i} of {len(dataloaders[phase])}\")\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            history[f'{phase}_loss'].append(epoch_loss)\n",
        "            history[f'{phase}_acc'].append(epoch_acc)\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "uYHty5B3c0tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before training\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Mango/Mango_002.jpg', model, class_names)\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Pineapple/Pineapple_021.jpg', model, class_names)\n"
      ],
      "metadata": {
        "id": "_JS0IIf3nomp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = train_model(model, criterion, optimizer, num_epochs=18)\n"
      ],
      "metadata": {
        "id": "XmK6M7JfdI6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\n",
        "    'train_loss': history['train_loss'],\n",
        "    'train_acc': [t.cpu().item() for t in history['train_acc']],\n",
        "    'test_loss': history['test_loss'],\n",
        "    'test_acc': [t.cpu().item() for t in history['test_acc']]\n",
        "}\n",
        "\n",
        "print(metrics)\n",
        "\n",
        "# Plot the training history\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(metrics['train_loss'], label='Train Loss')\n",
        "plt.plot(metrics['test_loss'], label='Test Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(metrics['train_acc'], label='Train Accuracy')\n",
        "plt.plot(metrics['test_acc'], label='Test Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t16NKwwMk8Ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained model\n",
        "torch.save(model, '/content/drive/MyDrive/Datasets/GroceryStoreDataset/complete_model.pth')\n"
      ],
      "metadata": {
        "id": "UIVE84gMkWdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Mango/Mango_002.jpg', model, class_names)\n",
        "predict_image('/content/drive/MyDrive/Datasets/GroceryStoreDataset/test/Pineapple/Pineapple_021.jpg', model, class_names)\n"
      ],
      "metadata": {
        "id": "dK1rXYLzdRf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project:\n",
        "\n",
        "1. Perform exploratory data analysis on the 'train' and 'test' datasets to calculate class imbalance (by comparing 'samples per class' across all the classes)\n",
        "2. Print confusion matrix, precision, recall and f1-score\n",
        "3. Show a grid of 6x4 images, with actual and predicted class for each of those\n",
        "\n",
        "\n",
        "### Bonus Project:\n",
        "\n",
        "1. Allow user to input the items they shopped using images, use model to identify grocery item based on confidence threshold. If confidence is low, ask user to manually input the item.\n",
        "2. Update the digital grocery cart\n",
        "3. Process the transaction by generating a transaction receipt\n"
      ],
      "metadata": {
        "id": "LTcyENYCtxXm"
      }
    }
  ]
}